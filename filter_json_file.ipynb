{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keywords for traffic incidents -- I let AI tools generate this list, but we can make this any list we want\n",
    "\n",
    "KEYWORDS = [\"traffic\", \"i40\", \"road\", \"accident\", \"crash\", \"incident\", \"delay\", \"congestion\", \"closure\", \"detour\", \"lane\", \"blocked\", \"exit\", \"ramp\", \"vehicle\", \"collision\", \"injury\", \"fatality\", \"police\", \"fire\", \"ambulance\", \"emergency\", \"hazard\", \"construction\", \"work\", \"zone\", \"sign\", \"signal\", \"light\", \"barrier\", \"guardrail\", \"shoulder\", \"median\", \"pavement\", \"asphalt\", \"concrete\", \"bridge\", \"overpass\", \"underpass\", \"culvert\", \"tunnel\", \"drainage\", \"ditch\", \"curb\", \"sidewalk\", \"crosswalk\", \"intersection\", \"roundabout\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def filter_jsonl(jsonl_file, keywords, output_file):\n",
    "    with open(jsonl_file, 'r') as f:\n",
    "        new_data = []\n",
    "        \n",
    "        # Process each line (JSON object) in the jsonl file\n",
    "        for line in f:\n",
    "            d = json.loads(line.strip())  # Parse the line as a JSON object\n",
    "\n",
    "            if 'body' in d:\n",
    "                text = d['body']\n",
    "            elif 'text' in d:\n",
    "                text = d['text']\n",
    "            elif 'title' in d:\n",
    "                text = d['title']\n",
    "            else:\n",
    "                continue\n",
    "            # Check if the 'text' key exists in the JSON object\n",
    "            # Remove punctuation and make all text lowercase\n",
    "            text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "\n",
    "            # Check if any of the keywords are in the 'text' field\n",
    "            for k in keywords:\n",
    "                if k in text:\n",
    "                    new_data.append(d)\n",
    "                    break  # If a keyword matches, no need to check further for this object\n",
    "    \n",
    "    # Save the filtered data to a new jsonl file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for item in new_data:\n",
    "            f.write(json.dumps(item) + '\\n')  # Write each filtered object as a new line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_jsonl(\"Data/r_nashville_posts.jsonl\", KEYWORDS, \"Data/filtered_r_nashville_posts.jsonl\")\n",
    "filter_jsonl(\"Data/r_nashville_comments.jsonl\", KEYWORDS, \"Data/filtered_r_nashville_comments.jsonl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trafficfeedback",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
